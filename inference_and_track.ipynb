{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import init_detector, inference_detector\n",
    "import mmcv\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv demo_vids/ ../../data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect and Track\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, load the ocr results, model weights and the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Path to OCR of the video\n",
    "data = open('../../data/ocr_results/results/ocr_with_gameclockrunning/2018-11-28_Virginia_at_Maryland/2018-11-28_Virginia_at_Maryland_ocr.json')\n",
    "data = json.load(data)\n",
    "\n",
    "### Config and model weights path\n",
    "config_file = 'configs/yolo/custom_yolov3_d53_mstrain-608_273e_coco.py'\n",
    "checkpoint_file = 'work_dirs/yolov3_d53_mstrain-608_273e_coco/epoch_273.pth'\n",
    "\n",
    "### Path to the video\n",
    "video_path = '../../data/videos/videos/2018-11-28_Virginia_at_Maryland.mp4'\n",
    "\n",
    "# build the model from a config file and a checkpoint file\n",
    "model = init_detector(config_file, checkpoint_file, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "code_folding": [
     19
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5fa63cf6ca84dd7a39ebb69e95087f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=124065.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)\n",
    "### Comment if you want to DEBUG\n",
    "logging.disable(logging.DEBUG)\n",
    "\n",
    "### Load the video using MMCV\n",
    "video = mmcv.VideoReader(video_path)\n",
    "\n",
    "### Temp variables\n",
    "en = 0\n",
    "proc = 0\n",
    "pbar = tqdm(total=video.frame_cnt)\n",
    "has_pred = 0\n",
    "\n",
    "\n",
    "### Create the tracker\n",
    "tracker = Tracker()\n",
    "\n",
    "### Start prediction\n",
    "for frame in video:\n",
    "    \n",
    "    ### Check if it is game moment using OCR\n",
    "    idx = str(en)\n",
    "    if not data['results'][idx]['score_bug_present'] or not data['results'][idx]['game_clock_running']:\n",
    "        en += 1\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    ### Predict the image and update stats\n",
    "    result = inference_detector(model, frame)\n",
    "    if len(result[0]) != 0: has_pred+=1\n",
    "        \n",
    "    ### Update tracker results\n",
    "    tracker.update(result)\n",
    "    \n",
    "    ### Update stats\n",
    "    en += 1\n",
    "    proc += 1\n",
    "    if proc > 600: break  \n",
    "    pbar.update(1)\n",
    "    \n",
    "    \n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(601, 601, 12.398399120853863)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Here, I check the number of collected detection and processed frames\n",
    "print(len(tracker.current_tracks), proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Here I run the function which search for missing detections intervals in tracker.current_tracks \n",
    "### and interpolates its values. The below threshold is pointing how many missed values to interpolate.\n",
    "how_much_to_interpoate = 6\n",
    "tracker.calc_missing_intervals(how_much_to_interpoate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "code_folding": [
     12,
     16,
     131,
     157
    ]
   },
   "outputs": [],
   "source": [
    "class Tracker():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.current_tracks = []  ### List of all tracks \n",
    "        self.temp_tracks = [] ### List of temporary tracks\n",
    "\n",
    "        self.temp_track_len = 3 ### How much tracks to collect before merging into main track\n",
    "        self.thresh_distance = 13 ### Euclidean distance threshold\n",
    "        self.avg_dist = []\n",
    "   \n",
    "\n",
    "    def convert_to_center(self, result):\n",
    "        return np.array([int((result[2] + result[0])/2), int((result[3] + result[1])/2)])\n",
    "\n",
    "    \n",
    "    def update(self, result):\n",
    "        \n",
    "        ### Check if we have any detections\n",
    "        if len(result[0])==0:  \n",
    "            \n",
    "            self.current_tracks.append(None)\n",
    "            self.temp_tracks = []\n",
    "            self.zero_res = result\n",
    "            \n",
    "        elif len(result[0])==1:\n",
    "            self.single_res = result[0][0]\n",
    "            \n",
    "            logging.debug(\"SINGLE RES\")\n",
    "\n",
    "            ### If we don't have approved tracks or no good history\n",
    "            if len(self.current_tracks)==0 or self.current_tracks[-1] is None:\n",
    "                logging.debug(\"NONE TRACK CONTINUED\")\n",
    "                ### if we don't temporary tracks we update temp tracks or we lost the track, else we check its distance to previous temp track\n",
    "                if len(self.temp_tracks)==0:\n",
    "                    self.temp_tracks.append(result[0][0])\n",
    "                    self.current_tracks.append(None)\n",
    "\n",
    "                else:\n",
    "                    curr_center = self.convert_to_center(result[0][0])\n",
    "                    last_center = self.convert_to_center(self.temp_tracks[-1])\n",
    "                    self.avg_dist.append(np.linalg.norm(curr_center  - last_center))\n",
    "                    \n",
    "                    if np.linalg.norm(curr_center  - last_center) <  self.thresh_distance:\n",
    "                        logging.debug(\"DIST CRITERIA SATISFIED\")\n",
    "                        self.temp_tracks.append(result[0][0]) \n",
    "                        \n",
    "                        if len(self.temp_tracks) < self.temp_track_len:\n",
    "                            self.current_tracks.append(None)\n",
    "                        else:\n",
    "                            logging.debug(\"CURRENT_TRACK UPDATED-------------------\")\n",
    "                            self.current_tracks.append(None)\n",
    "                            self.current_tracks[-len(self.temp_tracks):] = self.temp_tracks.copy()\n",
    "                            self.temp_tracks = []\n",
    "\n",
    "                    else:\n",
    "                        self.current_tracks.append(None)\n",
    "                        self.current_tracks[-(len(self.temp_tracks)+1):] = [None for _ in range(len(self.temp_tracks)+1)]\n",
    "                        self.temp_tracks = []\n",
    "\n",
    "            else:\n",
    "#                 self.temp_tracks = []\n",
    "                ### Now, we work with tracks that have history greater than 5\n",
    "                logging.debug(\"CURRENT TRACK CONTINUED\")\n",
    "                curr_center = self.convert_to_center(result[0][0])\n",
    "                last_canter = self.convert_to_center(self.current_tracks[-1])\n",
    "                \n",
    "                if np.linalg.norm(curr_center - last_canter) <  self.thresh_distance:\n",
    "                    logging.debug(\"GOOD TRACK APPENDED\")\n",
    "                    self.avg_dist.append(np.linalg.norm(curr_center - last_canter))\n",
    "                    self.current_tracks.append(result[0][0])           \n",
    "                else:\n",
    "                    logging.debug(\"BAD TRACK APPENDED\")\n",
    "                    self.current_tracks.append(None)\n",
    "\n",
    "        elif len(result[0])>1:\n",
    "            self.multi_res = result\n",
    "            \n",
    "            logging.debug(\"MULTI RES\")\n",
    "#             self.temp_tracks = []\n",
    "            \n",
    "            if len(self.current_tracks)==0 or self.current_tracks[-1] is None:\n",
    "                \n",
    "                if len(self.temp_tracks)>0:\n",
    "                    appended = False\n",
    "                    \n",
    "                    for i in range(len(result[0])):\n",
    "\n",
    "                        curr_res = result[0][i]\n",
    "                        curr_center = self.convert_to_center(curr_res)\n",
    "                        last_center = self.convert_to_center(self.temp_tracks[-1])\n",
    "                        if np.linalg.norm(curr_center - last_center) <  self.thresh_distance:\n",
    "                                                                           \n",
    "                            self.temp_tracks.append(result[0][0]) \n",
    "                            if len(self.temp_tracks) < self.temp_track_len:\n",
    "                                self.current_tracks.append(None)\n",
    "                            else:\n",
    "                                logging.debug(\"CURRENT_TRACK UPDATED-------------------\")\n",
    "                                self.current_tracks.append(None)\n",
    "                                self.current_tracks[-len(self.temp_tracks):] = self.temp_tracks.copy()\n",
    "                                self.temp_tracks = []                         \n",
    "                            \n",
    "                            appended = True                       \n",
    "                            break\n",
    "                            \n",
    "                    if not appended:\n",
    "                        self.current_tracks.append(None)\n",
    "                        self.current_tracks[-(len(self.temp_tracks)+1):] = [None for _ in range(len(self.temp_tracks)+1)]\n",
    "                        self.temp_tracks = []    \n",
    "                        \n",
    "                else:\n",
    "                    self.current_tracks.append(None)\n",
    "            \n",
    "            else:\n",
    "#                 self.current_tracks.append(None)\n",
    "                self.temp_tracks = []\n",
    "                appended = False\n",
    "                for i in range(len(result[0])):\n",
    "\n",
    "                    curr_res = result[0][i]\n",
    "                    curr_center = self.convert_to_center(curr_res)\n",
    "                    last_center = self.convert_to_center(self.current_tracks[-1])\n",
    "                    if np.linalg.norm(curr_center - last_center) <  self.thresh_distance:\n",
    "                        appended = True\n",
    "                        self.current_tracks.append(curr_res)                         \n",
    "                        break\n",
    "\n",
    "                if not appended:\n",
    "                    self.current_tracks.append(None)\n",
    "                    \n",
    "                    \n",
    "    def calc_missing_intervals(self, length=2):\n",
    "    \n",
    "        i=0\n",
    "        j=0\n",
    "        misses = 0\n",
    "        while i<len(self.current_tracks) and j<len(self.current_tracks):\n",
    "            if self.current_tracks[i] is not None:\n",
    "                i += 1\n",
    "                j = i       \n",
    "            elif self.current_tracks[i] is None and self.current_tracks[j] is None:\n",
    "                j += 1\n",
    "            elif self.current_tracks[i] is None and self.current_tracks[j] is not None and 0 < (j - i) <= length:\n",
    "                interp_tracks = self.interpolate_bboxes(self.current_tracks[i-1:j+1])\n",
    "                self.current_tracks[i-1:j+1] = interp_tracks                \n",
    "                i = j           \n",
    "                misses += 1           \n",
    "            elif self.current_tracks[i] is None and self.current_tracks[j] is not None and (j - i) > length:\n",
    "                i=j\n",
    "\n",
    "\n",
    "        if 0 < (j - i) <= length:\n",
    "            misses += 1\n",
    "\n",
    "        return misses\n",
    "    \n",
    "    \n",
    "    def interpolate_bboxes(self, tracks):\n",
    "        first = tracks[0]\n",
    "        last = tracks[-1]\n",
    "\n",
    "        first_center = [ (first[2] + first[0]) / 2, (first[3] + first[1]) / 2]\n",
    "        last_center = [(last[2] + last[0]) / 2, (last[3] + last[1]) / 2]\n",
    "\n",
    "        half_width = ((abs(first[2] - first[0]) + abs(last[2] - last[0])) / 2) / 2\n",
    "        half_height = ((abs(first[3] - first[1]) + abs(last[3] - last[1])) / 2) / 2\n",
    "\n",
    "\n",
    "        i = 1\n",
    "\n",
    "        while i < len(tracks)-1:\n",
    "            new_x = first_center[0] + ((i + 1) / len(tracks)) * (last_center[0] - first_center[0])\n",
    "            new_y = first_center[1] + ((i + 1) / len(tracks)) * (last_center[1] - first_center[1])\n",
    "\n",
    "            new_bbox = np.array([new_x - half_width, new_y - half_height, new_x + half_width, new_y + half_height, first[-1]])\n",
    "\n",
    "            tracks[i] = new_bbox\n",
    "\n",
    "            i+=1\n",
    "\n",
    "\n",
    "        return tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize after tracker results\n",
    "\n",
    "### After we process the video, we have all the processed detections in tracker.current_tracks (list of bboxes). The indecies of this list corresponds to index of the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test a video and show the results\n",
    "video = mmcv.VideoReader('../../data/videos/videos/2018-11-28_Virginia_at_Maryland.mp4')\n",
    "out = cv2.VideoWriter('output_tracker.mp4',cv2.VideoWriter_fourcc(*'MP4V'), 15, (1280,720))\n",
    "\n",
    "en = 0\n",
    "proc = 0\n",
    "not_none = 0\n",
    "for frame in video:\n",
    "    idx = str(en)\n",
    "    if not data['results'][idx]['score_bug_present'] or not data['results'][idx]['game_clock_running']:\n",
    "        en += 1\n",
    "        continue\n",
    "    \n",
    "    if tracker.current_tracks[proc] is not None:\n",
    "        not_none += 1 \n",
    "        result = np.expand_dims(tracker.current_tracks[proc][:4], axis=0)\n",
    "        frame = mmcv.imshow_bboxes(frame, result, show=False, thickness=1, colors=['green'])\n",
    "\n",
    "    \n",
    "    out.write(frame)\n",
    "\n",
    "    en += 1\n",
    "    proc += 1\n",
    "    if proc > 500:break\n",
    "    \n",
    "    \n",
    "    \n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = mmcv.VideoReader('../../data/videos/videos/2018-11-28_Virginia_at_Maryland.mp4')\n",
    "\n",
    "en = 0\n",
    "proc = 0\n",
    "not_none = 0\n",
    "for frame in video:\n",
    "    idx = str(en)\n",
    "    if not data['results'][idx]['score_bug_present'] or not data['results'][idx]['game_clock_running'] or en<1000:\n",
    "        en += 1\n",
    "        continue\n",
    "    \n",
    "    if proc%5==0:\n",
    "        cv2.imwrite('../../data/single_frames/frame_{:05}.jpg'.format(int(proc/5)), frame)\n",
    "    proc += 1\n",
    "    if proc>160:break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['frame_00000.jpg',\n",
       " 'frame_00001.jpg',\n",
       " 'frame_00002.jpg',\n",
       " 'frame_00003.jpg',\n",
       " 'frame_00004.jpg',\n",
       " 'frame_00005.jpg',\n",
       " 'frame_00006.jpg',\n",
       " 'frame_00007.jpg',\n",
       " 'frame_00008.jpg',\n",
       " 'frame_00009.jpg',\n",
       " 'frame_00010.jpg',\n",
       " 'frame_00011.jpg',\n",
       " 'frame_00012.jpg',\n",
       " 'frame_00013.jpg',\n",
       " 'frame_00014.jpg',\n",
       " 'frame_00015.jpg',\n",
       " 'frame_00016.jpg',\n",
       " 'frame_00017.jpg',\n",
       " 'frame_00018.jpg',\n",
       " 'frame_00019.jpg',\n",
       " 'frame_00020.jpg',\n",
       " 'frame_00021.jpg',\n",
       " 'frame_00022.jpg',\n",
       " 'frame_00023.jpg',\n",
       " 'frame_00024.jpg',\n",
       " 'frame_00025.jpg',\n",
       " 'frame_00026.jpg',\n",
       " 'frame_00027.jpg',\n",
       " 'frame_00028.jpg',\n",
       " 'frame_00029.jpg',\n",
       " 'frame_00030.jpg',\n",
       " 'frame_00031.jpg',\n",
       " 'frame_00032.jpg']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(os.listdir('../../data/single_frames/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: ../../data/single_frames/ (stored 0%)\n",
      "  adding: ../../data/single_frames/frame_00025.jpg (deflated 0%)\n",
      "  adding: ../../data/single_frames/frame_00004.jpg (deflated 1%)\n",
      "  adding: ../../data/single_frames/frame_00024.jpg (deflated 0%)\n",
      "  adding: ../../data/single_frames/frame_00028.jpg (deflated 0%)\n",
      "  adding: ../../data/single_frames/frame_00031.jpg (deflated 0%)\n",
      "  adding: ../../data/single_frames/frame_00007.jpg (deflated 1%)\n",
      "  adding: ../../data/single_frames/frame_00018.jpg (deflated 0%)\n",
      "  adding: ../../data/single_frames/frame_00013.jpg (deflated 1%)\n",
      "  adding: ../../data/single_frames/frame_00030.jpg (deflated 0%)\n",
      "  adding: ../../data/single_frames/frame_00006.jpg (deflated 0%)\n",
      "  adding: ../../data/single_frames/frame_00032.jpg (deflated 0%)\n",
      "  adding: ../../data/single_frames/frame_00017.jpg (deflated 0%)\n",
      "  adding: ../../data/single_frames/frame_00011.jpg (deflated 0%)\n",
      "  adding: ../../data/single_frames/frame_00008.jpg (deflated 1%)\n",
      "  adding: ../../data/single_frames/frame_00016.jpg (deflated 0%)\n",
      "  adding: ../../data/single_frames/frame_00021.jpg (deflated 0%)\n",
      "  adding: ../../data/single_frames/frame_00000.jpg (deflated 1%)\n",
      "  adding: ../../data/single_frames/frame_00015.jpg (deflated 0%)\n",
      "  adding: ../../data/single_frames/frame_00014.jpg (deflated 0%)\n",
      "  adding: ../../data/single_frames/frame_00026.jpg (deflated 0%)\n",
      "  adding: ../../data/single_frames/frame_00012.jpg (deflated 1%)\n",
      "  adding: ../../data/single_frames/frame_00003.jpg (deflated 1%)\n",
      "  adding: ../../data/single_frames/frame_00022.jpg (deflated 0%)\n",
      "  adding: ../../data/single_frames/frame_00005.jpg (deflated 1%)\n",
      "  adding: ../../data/single_frames/frame_00027.jpg (deflated 0%)\n",
      "  adding: ../../data/single_frames/frame_00019.jpg (deflated 0%)\n",
      "  adding: ../../data/single_frames/frame_00029.jpg (deflated 0%)\n",
      "  adding: ../../data/single_frames/frame_00010.jpg (deflated 0%)\n",
      "  adding: ../../data/single_frames/frame_00009.jpg (deflated 1%)\n",
      "  adding: ../../data/single_frames/frame_00002.jpg (deflated 1%)\n",
      "  adding: ../../data/single_frames/frame_00023.jpg (deflated 0%)\n",
      "  adding: ../../data/single_frames/frame_00001.jpg (deflated 1%)\n",
      "  adding: ../../data/single_frames/frame_00020.jpg (deflated 1%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r frames.zip ../../data/single_frames/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm ../../data/single_frames/*\n",
    "!rm frames.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  zip\n",
      "0 upgraded, 1 newly installed, 0 to remove and 26 not upgraded.\n",
      "Need to get 167 kB of archives.\n",
      "After this operation, 638 kB of additional disk space will be used.\n",
      "Get:1 http://us-east-2.ec2.archive.ubuntu.com/ubuntu bionic/main amd64 zip amd64 3.0-11build1 [167 kB]\n",
      "Fetched 167 kB in 0s (1426 kB/s)\u001b[33m\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package zip.\n",
      "(Reading database ... 256411 files and directories currently installed.)\n",
      "Preparing to unpack .../zip_3.0-11build1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 17%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Unpacking zip (3.0-11build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 50%]\u001b[49m\u001b[39m [#############################.............................] \u001b8Setting up zip (3.0-11build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 67%]\u001b[49m\u001b[39m [######################################....................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 83%]\u001b[49m\u001b[39m [################################################..........] \u001b8Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "!sudo apt install zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
